# Company Context

## Company Overview
**Mission**: Build comprehensive SaaS platform for internal business operations through AI-powered development teams.

## Current State
- **Phase**: First project operational and deployed
- **Active Projects**: 
  - AI Company Framework development (completed)
  - Flexible Office Scraper platform (operational with 40 operators loaded)
- **Priority**: Execute domain discovery pipeline for flexible office space data collection

## Active Teams
- **Scraping Team**: Fully operational with context, memory, tools, and logging systems

## Current Goals
1. ✅ Complete company infrastructure setup
2. ✅ Deploy functional scraping team with context and memory systems
3. ✅ Complete flexible office scraper SaaS platform with 40 operators loaded
4. ⚡ Execute domain discovery and verification pipeline for office space data
5. Prepare framework for additional teams (development, security, design)

## Company Resources
- **Technology Stack**: Node.js, Anthropic SDK, Puppeteer, Cheerio, CSV processing
- **Infrastructure**: File-based system with hierarchical logging and context management
- **Navigation System**: Complete command structure for accessing all company resources
- **Human Leadership**: Levi (Boss) directing all operations

## Next Milestones
- [x] Complete scraping team setup
- [x] Receive specific scraping project requirements from Levi
- [x] First scraping project deployment (Flexible Office Scraper)
- [x] Load initial operator data (40 flexible office operators)
- [ ] Execute domain discovery pipeline 
- [ ] Execute domain verification pipeline
- [ ] Scale to 1,000+ operators as specified
- [ ] Validation of audit trail and logging systems in real operation
- [ ] Expansion planning for additional teams

## Decision Log
- 2024-08-26: Adopted file-based company structure over database approach
- 2024-08-26: Decided on sequential team operations rather than parallel execution
- 2024-08-26: Prioritized scraping team as first operational unit
- 2024-08-26: Implemented office-first scraping architecture for efficient rescanning
- 2024-08-26: Used SQLite for immediate deployment over PostgreSQL for development speed

---
**Last Updated**: 2024-08-26T17:00:00Z
**Next Review**: After domain discovery pipeline execution